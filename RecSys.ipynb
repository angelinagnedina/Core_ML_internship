{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f71f6e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, eye, hstack\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "from utils.data_processing import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cad7ca",
   "metadata": {},
   "source": [
    "Начнём с использования только рейтингов фильма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f39dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/rating.csv').iloc[:, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd42c1",
   "metadata": {},
   "source": [
    "Датасет довольно большой, давайте выберем из него рандомные 2 миллиона строчек. (Немного забегая вперёд: неплохо бы нашей модели уметь давать хорошие рекомендации активным пользователям, потому что тогда есть надежда, что алгоритм будет давать хорошие рекомендации и тем, о ком мы имеем мало данных. Поэтому отбёрём в датасет строчки с самыми активными пользователями.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f394c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_users = data.userId.value_counts().index - 1\n",
    "data_part_1 = data.loc[data['userId'].isin(active_users[:5000])]\n",
    "\n",
    "data_part_2 = data.loc[data['userId'].isin(active_users[:5000]) == False]\n",
    "rand_users = np.random.choice(data_part_2.shape[0], \n",
    "                              size=555000, replace=False)\n",
    "# Датасет для подбора гиперпараметров\n",
    "users_for_hyper_tuning = np.random.choice(data_part_2.shape[0], \n",
    "                                          size=5000, replace=False)\n",
    "val_data = data_part_2.iloc[users_for_hyper_tuning, :].sort_values(['userId', 'movieId'])\n",
    "val_data = val_data.reset_index(drop=True)\n",
    "\n",
    "data_part_2 = data_part_2.iloc[rand_users, :].sort_values(['userId', 'movieId'])\n",
    "\n",
    "data = pd.concat([data_part_1, data_part_2], axis=0).sort_values(['userId', 'movieId'])\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd3f99",
   "metadata": {},
   "source": [
    "Добавим две новые колонки в датасет, которые будут отвечать за новые индексы юзеров и фильмов, попавших в data - ***new_userId*** и ***new_movieId*** соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188685c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_dataset(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            data: pd.DataFrame, данные, в которых идентификаторы пользователей/фильмов\n",
    "              разбросаны в диапазоне [1, 138493] и [1, 131258] соответственно.\n",
    "        \n",
    "        Returns:\n",
    "            Датафрейм, где добавлены колонки с новыми id для пользователей фильмов в диапазоне\n",
    "              [1, кол-во уникальных пользователей/фильмов в data].\n",
    "    \"\"\"\n",
    "    user_unique = np.unique(data.userId)\n",
    "    item_unique = np.unique(data.movieId)\n",
    "    new_userId = dict([(user_unique[i], i + 1) for i in range(len(user_unique))])\n",
    "    new_movieId = dict([(item_unique[i], i + 1) for i in range(len(item_unique))])\n",
    "    col_1 = [int(new_userId[u]) for u in data.userId]\n",
    "    col_2 = [int(new_movieId[i]) for i in data.movieId]\n",
    "\n",
    "    new_data = pd.DataFrame(data = {'new_userId': col_1, 'new_movieId': col_2})\n",
    "    data = pd.concat([new_data, data], axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83e4a6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_userId</th>\n",
       "      <th>new_movieId</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2554</td>\n",
       "      <td>1</td>\n",
       "      <td>2692</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2860</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5798</td>\n",
       "      <td>1</td>\n",
       "      <td>6093</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6783</td>\n",
       "      <td>1</td>\n",
       "      <td>7164</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7642</td>\n",
       "      <td>1</td>\n",
       "      <td>8690</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_userId  new_movieId  userId  movieId  rating\n",
       "0           1         2554       1     2692     3.5\n",
       "1           1         2860       1     3000     3.5\n",
       "2           1         5798       1     6093     4.0\n",
       "3           1         6783       1     7164     3.5\n",
       "4           1         7642       1     8690     3.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = modify_dataset(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b1721",
   "metadata": {},
   "source": [
    "Создаём user-item матрицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "004c48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_interaction(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            data: pd.DataFrame - данные, содержащие id пользователей и фильмов, \n",
    "              а также рейтинги.\n",
    "        \n",
    "        Returns:\n",
    "            User-item матрицу.\n",
    "    \"\"\"\n",
    "    users = np.array(data['new_userId'])\n",
    "    items = np.array(data['new_movieId'])\n",
    "    rating = data['rating']\n",
    "    interaction_sparse = csr_matrix((rating, (users - 1, items - 1)), \n",
    "                                    shape=(max(users), max(items)))\n",
    "    \n",
    "    return interaction_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a249af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_sparse = make_interaction(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce9c8f",
   "metadata": {},
   "source": [
    "Разбивать на тренировочный и тестовый набор будем по следующему принципу: хотим уметь хорошо давать рекомендации активным пользователям, так как о них имеем больше информации и скорее всего эти люди заинтересованы продолжать потреблять много контента. Так же, если умеем неплохо давать рекомендации таким пользователям, есть шанс, что алгоритм будет давать неплохие советы и менее активным пользователям, чьё поведение не так хорошо известно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ee9ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(data: pd.DataFrame, interaction_sparse: csr_matrix,\n",
    "                   fraction: float, count: int):\n",
    "    \"\"\"\n",
    "        Args: \n",
    "            data: pd.DataFrame - данные для разбиения на тренировочную/тестовую выборки.\n",
    "            interaction_sparse: csr_matrix - user-item матрица.\n",
    "            fraction: float - доля пользователей, чьи рейтинги будут рассматриваться\n",
    "              для занесения в тестовый сет.\n",
    "            count: int - количество рейтингов, которое будет вноситься в тестовый сет.\n",
    "        \n",
    "        Returns:\n",
    "            train: csr_matrix - тренировочный сет.\n",
    "            test: csr_matrix - тестовый сет.\n",
    "            user_ind: id пользователей, чьи оценки были внесены в тестовый сет.\n",
    "    \"\"\"\n",
    "    active_users = data.new_userId.value_counts().index - 1\n",
    "    train, test, user_ind = train_test_split(interaction_sparse, active_users, \n",
    "                                             fraction, count)\n",
    "    \n",
    "    return train, test, user_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d23266b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, test_user_ind = get_train_test(data, interaction_sparse, 0.1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a73db",
   "metadata": {},
   "source": [
    "Импортируем метрики, по которым мы будем оценивать алгоритмы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9203253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import apk, ndcgk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd86b10",
   "metadata": {},
   "source": [
    "Почему выбраны метрики ***mean average precision at k*** и ***ndcg***? \n",
    "Обе метрики позволяют не только вывести самые релевантные объекты пользователю, но и учитывает порядок этих объектов (хочется на первых местах видеть более релевантные фильмы).   \n",
    "MAP@K хоть и является метрикой для случая, когда рейтинг - бинарная величина, но можно проделать некоторые манипуляции. Поместим текущие оценки в диапазон [0, 1] и установим порог p, после которого фильм с оценкой > p считаем релевантным. Тогда метрика позволит оценить способность алгоритма давать неплохие рекомендации.  \n",
    "Ndcg же работает и для случая, когда рейтинг - небинарная величина."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69815aa2",
   "metadata": {},
   "source": [
    "Теперь выберем алгоритм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d79e082",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8c2e7",
   "metadata": {},
   "source": [
    "Создадим функцию для подсчёта метрик на тестовом сете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a46c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model: LightFM, test: csr_matrix, item_features,\n",
    "                      stop: int, k: int, test_user_ind, num_of_items):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            model: LightFM - модель, делающая предсказания.\n",
    "            test: csr_matrix - тестовый сет.\n",
    "            item_features: None, если не добавляем доп. фичи фильмам, иначе\n",
    "              это csr_matrix.\n",
    "            stop: int - величина, которую пришлось добавить из-за длительных расчётов.\n",
    "              По сути просто прерывает подсчёт метрики на каком-то пользователе из тестового сета.\n",
    "            k: int - кол-во рекомендаций, которые алгоритм даёт пользователю.\n",
    "            test_user_ind: идентификаторы пользователей из тестового сета. \n",
    "            num_of_items: всего item'ов.\n",
    "        \n",
    "        Returns:\n",
    "            Метрики mean_nDCG@K, MAP@k.\n",
    "    \"\"\"\n",
    "    test_arr = test.toarray()\n",
    "    ndcgk_per_user = []\n",
    "    apk_per_user = []\n",
    "    for i in test_user_ind[:stop]:\n",
    "        predictions = model.predict(int(i), np.arange(num_of_items), \n",
    "                                    item_features=item_features)\n",
    "        true_val = test_arr[i]\n",
    "        ndcgk_per_user.append(ndcgk(predictions, true_val, k))\n",
    "        apk_per_user.append(apk(predictions, true_val, k, 4.0))\n",
    "\n",
    "    mean_ndcgk = np.sum(ndcgk_per_user)/len(ndcgk_per_user)\n",
    "    mapk = np.sum(apk_per_user)/len(apk_per_user)\n",
    "    print('Mean ndcgk:', mean_ndcgk)\n",
    "    print('Mapk:', mapk)\n",
    "    \n",
    "    return mean_ndcgk, mapk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be74d62",
   "metadata": {},
   "source": [
    "Подберём гиперпараметры на data_val сете. Будем выбирать no_components и learning rate поиском по сетке. В качестве loss'а будем брать warp, так как на практике он себя лучше показывает, чем bpr. Разобьём data_val также на тренировочный и тестовый сет, обучим эпох 30, потом сравним метрики. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c62f9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = modify_dataset(val_data)\n",
    "val_interaction_sparse = make_interaction(val_data)\n",
    "val_train, val_test, val_user_ind = get_train_test(val_data, val_interaction_sparse, 0.2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bf9b0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_components: 20, learning_rate: 0.1\n",
      "Mean ndcgk: 0.011721584189550405\n",
      "Mapk: 0.0\n",
      "no_components: 20, learning_rate: 0.05\n",
      "Mean ndcgk: 0.009849811262948113\n",
      "Mapk: 0.0\n",
      "no_components: 20, learning_rate: 0.005\n",
      "Mean ndcgk: 0.010675659398161548\n",
      "Mapk: 0.0\n",
      "no_components: 30, learning_rate: 0.1\n",
      "Mean ndcgk: 0.012757507005870302\n",
      "Mapk: 0.0\n",
      "no_components: 30, learning_rate: 0.05\n",
      "Mean ndcgk: 0.01247858584119305\n",
      "Mapk: 0.0\n",
      "no_components: 30, learning_rate: 0.005\n",
      "Mean ndcgk: 0.011326454040079937\n",
      "Mapk: 0.0\n",
      "no_components: 40, learning_rate: 0.1\n",
      "Mean ndcgk: 0.010688565909038888\n",
      "Mapk: 0.0\n",
      "no_components: 40, learning_rate: 0.05\n",
      "Mean ndcgk: 0.010261757866642273\n",
      "Mapk: 0.0\n",
      "no_components: 40, learning_rate: 0.005\n",
      "Mean ndcgk: 0.010034184609037846\n",
      "Mapk: 0.0\n"
     ]
    }
   ],
   "source": [
    "no_components = [20, 30, 40] #Рассматриваю такие значения, потому что при бОльших считается довольно долго, к сожалению.\n",
    "lr_space = [0.1, 0.05, 0.005]\n",
    "model_metrics = [{'mean_ndcgk': 0.0, 'mapk': 0.0} for _ in range(9)]\n",
    "cnt = 0\n",
    "\n",
    "for n_comp in no_components:\n",
    "    for lr in lr_space:\n",
    "        model = LightFM(no_components=n_comp, \n",
    "                learning_rate=lr, \n",
    "                loss='warp', \n",
    "                random_state=7)\n",
    "        model.fit(val_train, epochs=30)\n",
    "        print(f'no_components: {n_comp}, learning_rate: {lr}')\n",
    "        mean_ndcgk, mapk = calculate_metrics(model, val_test, None, len(val_user_ind),\n",
    "                                             10, val_user_ind, max(val_data['new_movieId']))\n",
    "        model_metrics[cnt]['mean_ndcgk'] = mean_ndcgk\n",
    "        model_metrics[cnt]['mapk'] = mapk    \n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc895ad",
   "metadata": {},
   "source": [
    "Возьмём в качестве гиперпараметров значения:  no_components = 30,  learning_rate = 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17c24048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ndcgk: 0.07205956776447531\n",
      "Mapk: 0.0003255291005291005\n"
     ]
    }
   ],
   "source": [
    "model = LightFM(no_components=30, \n",
    "                learning_rate=0.1, \n",
    "                loss='warp', \n",
    "                random_state=7)\n",
    "\n",
    "model.fit(train, epochs=50)\n",
    "# Ограничимся подсчётом метрики для 3000 пользователей из тестового сета, для быстроты вычислений.\n",
    "mean_ndcgk, mapk = calculate_metrics(model, test, None, 3000, \n",
    "                                     10, test_user_ind, max(data['new_movieId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461f28b",
   "metadata": {},
   "source": [
    "Теперь импортируем дополнительные сведения о фильме. Добавим в качестве фичей для фильма те теги, которые релевантны хотя бы на 0.25, а также укажем, к какому жанру относится фильм (если вместо жанра стоит (no genres listed), то переопределяем значение на False). Мотивация ясна: фильмы с похожими жанрами и тегами можно будет рекомендовать пользователю, если обнаружится тенденция в его предпочтениях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c803271",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item_tag_scores = pd.read_csv('data/genome_scores.csv')\n",
    "data_item_tags = pd.read_csv('data/genome_tags.csv')\n",
    "# data_item_tags_info - объединение двух предыдущих по общей колонке movieId, чтобы соотнести id тэгов с их названиями\n",
    "data_item_tags_info = pd.merge(data_item_tags, data_item_tag_scores).iloc[:, 1:]\n",
    "data_item_tags_info = data_item_tags_info.sort_values('movieId').reset_index(drop=True)\n",
    "data_genres = pd.read_csv('data/movie.csv').replace('(no genres listed)', value=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90ac30a",
   "metadata": {},
   "source": [
    "Создадим фичи для фильмов (добавляем также per-item фичи, чтобы у каждого фильма было закодировано one-hot кодировкой его new_movieId)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ede924f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_item_features(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            data: pd.DataFrame - данные.\n",
    "        \n",
    "        Returns:\n",
    "            item_features: csr_matrix - матрицу фичей для фильмов. \n",
    "    \"\"\"\n",
    "    itemId = np.unique(data.new_movieId)\n",
    "    item_features = [{} for i in itemId]\n",
    "    for id in itemId:\n",
    "        corresponding_movieId = data.movieId[data.new_movieId == id].iloc[0]\n",
    "        info_per_item = data_item_tags_info.loc[data_item_tags_info['movieId'] == corresponding_movieId]\n",
    "        info_per_item = info_per_item.loc[info_per_item['relevance'] >= 0.25]\n",
    "        for row in range(info_per_item.shape[0]):\n",
    "            tag = info_per_item.tag.iat[row]\n",
    "            relevance = info_per_item.relevance.iat[row]\n",
    "            item_features[id - 1][f'{tag}'] = relevance\n",
    "\n",
    "        genres_per_item = data_genres.loc[data_genres['movieId'] == corresponding_movieId]['genres'].iloc[0]\n",
    "        if genres_per_item:\n",
    "            for genre in genres_per_item.split('|'):\n",
    "                item_features[id - 1][genre] = 1\n",
    "    \n",
    "    dv = DictVectorizer()\n",
    "    item_features = dv.fit_transform(item_features)\n",
    "    eye_matrix = eye(item_features.shape[0], item_features.shape[0]).tocsr()\n",
    "    item_features = hstack((eye_matrix, item_features)).tocsr().astype(np.float32)\n",
    "    \n",
    "    return item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09ea3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = make_item_features(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7557698",
   "metadata": {},
   "source": [
    "Подберём гиперпараметры для модели с фичами для фильмов. Обучаться будем 20 эпох вследствие несовершенства вычислительных ресурсов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e055c36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_components: 20, learning_rate: 0.1\n",
      "Mean ndcgk: 0.0020866461283098087\n",
      "Mapk: 0.0\n",
      "no_components: 20, learning_rate: 0.05\n",
      "Mean ndcgk: 0.0022076942197074936\n",
      "Mapk: 0.0\n",
      "no_components: 20, learning_rate: 0.005\n",
      "Mean ndcgk: 0.003670895598052078\n",
      "Mapk: 0.0\n",
      "no_components: 30, learning_rate: 0.1\n",
      "Mean ndcgk: 0.0003585036904467763\n",
      "Mapk: 0.0\n",
      "no_components: 30, learning_rate: 0.05\n",
      "Mean ndcgk: 0.00022029655131030704\n",
      "Mapk: 0.0\n",
      "no_components: 30, learning_rate: 0.005\n",
      "Mean ndcgk: 0.0011589004193791168\n",
      "Mapk: 0.0\n",
      "no_components: 40, learning_rate: 0.1\n",
      "Mean ndcgk: 0.0004576796578888343\n",
      "Mapk: 0.0\n",
      "no_components: 40, learning_rate: 0.05\n",
      "Mean ndcgk: 0.004514112352265212\n",
      "Mapk: 0.0\n",
      "no_components: 40, learning_rate: 0.005\n",
      "Mean ndcgk: 0.00333057386039487\n",
      "Mapk: 0.0\n"
     ]
    }
   ],
   "source": [
    "val_item_features = make_item_features(val_data)\n",
    "model_with_features_metrics = [{'mean_ndcgk': 0.0, 'mapk': 0.0} for _ in range(9)]\n",
    "cnt = 0\n",
    "\n",
    "for n_comp in no_components:\n",
    "    for lr in lr_space:\n",
    "        model_with_features = LightFM(no_components=n_comp, \n",
    "                learning_rate=lr, \n",
    "                loss='warp', \n",
    "                random_state=7)\n",
    "        model_with_features.fit(val_train, item_features=val_item_features, epochs=20)\n",
    "        print(f'no_components: {n_comp}, learning_rate: {lr}')\n",
    "        mean_ndcgk, mapk = calculate_metrics(model_with_features, val_test, val_item_features,\n",
    "                                             len(val_user_ind), 10, val_user_ind, \n",
    "                                             max(val_data['new_movieId']))\n",
    "        model_with_features_metrics[cnt]['mean_ndcgk'] = mean_ndcgk\n",
    "        model_with_features_metrics[cnt]['mapk'] = mapk    \n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ac974",
   "metadata": {},
   "source": [
    "Обучим модель со следующими гиперпараметрами: no_components = 40,  learning_rate = 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0272028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ndcgk: 0.05526614095399426\n",
      "Mapk: 0.5767131029464363\n"
     ]
    }
   ],
   "source": [
    "model_with_features = LightFM(no_components=40, \n",
    "                learning_rate=0.05, \n",
    "                loss='warp', \n",
    "                random_state=7)\n",
    "\n",
    "model_with_features.fit(train, item_features=item_features, epochs=50)\n",
    "mean_ndcgk, mapk = calculate_metrics(model_with_features, test, item_features,\n",
    "                                     3000, 10, test_user_ind, max(data['new_movieId']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7df38",
   "metadata": {},
   "source": [
    "Теперь сравним с бейзлайном (просто выдавать самые популярные фильмы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1421c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_k(data: pd.DataFrame, k: int):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            data: pd.DataFrame - данные.\n",
    "            k: int - кол-во рекомендаций, которые алгоритм даёт пользователю.\n",
    "            \n",
    "        Returns:\n",
    "            Рекомендации, составленные из самых популярных фильмов с рейтингом >= 4.0.\n",
    "    \"\"\"\n",
    "    popular_films = data.new_movieId.loc[data.rating >= 4.0].value_counts().index - 1\n",
    "    n_films = len(np.unique(data.new_movieId))\n",
    "    pred = np.zeros(shape = n_films)\n",
    "    pred[popular_films[:k]] = 5.0\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e2f8c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ndcgk: 0.11852914487178769\n",
      "Mapk: 0.05323333333333333\n"
     ]
    }
   ],
   "source": [
    "test_arr = test.toarray()\n",
    "ndcgk_per_user_base = []\n",
    "apk_per_user_base = []\n",
    "predictions = predictions_k(data, 10)\n",
    "for i in test_user_ind[:3000]:\n",
    "    true_val = test_arr[i]\n",
    "    ndcgk_per_user_base.append(ndcgk(predictions, true_val, 10))\n",
    "    apk_per_user_base.append(apk(predictions, true_val, 10, 4.0))\n",
    "\n",
    "mean_ndcgk = np.sum(ndcgk_per_user_base)/len(ndcgk_per_user_base)\n",
    "mapk = np.sum(apk_per_user_base)/len(apk_per_user_base)\n",
    "print('Mean ndcgk:', mean_ndcgk)\n",
    "print('Mapk:', mapk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c40d5ee",
   "metadata": {},
   "source": [
    "***Вывод*** \n",
    "\n",
    "С метрикой ***mean_nDCG@K*** происходит что-то странное, раз на baseline'е она выдаёт лучше результат, чем на обученных моделях, возможно проблемы с реализацией, которые не удалось отследить. \n",
    "\n",
    "А вот судя по ***MAP@K*** модель с фичами лучше даёт рекомендации пользователям. Изначально было предположение, что из-за наличия доп. информации о фильмах модель может переобучиться и соответственно хуже выдавать фильмы. Но, видимо, тщательный отбор признаков помог уловить тенденции в предпочтениях пользователей. \n",
    "\n",
    "Хотелось бы конечно обучить модели на всех имеющихся данных, тогда возможно и простая модель с рейтингами показала бы лучше результаты, но такие вычисления, к сожалению, очень затратно производить на имеющемся оборудовании. Также не исключено, что даже чуть больший выбор гиперпараметров дал бы лучше результаты (была попытка обучить модель с фичами, у которых no_components = 60, но пришлось прервать вычисления из-за длительности вычислений). "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Необработанный формат ячейки",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
